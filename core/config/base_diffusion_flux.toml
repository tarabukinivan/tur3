ae = "/app/flux/ae.safetensors"                                                                                                                                      
apply_t5_attn_mask = true                                                                                                                                                      
bucket_no_upscale = true                                                                                                                                                       
bucket_reso_steps = 64                                                                                                                                                         
cache_latents = true                                                                                                                                                           
cache_latents_to_disk = false
caption_extension = ".txt"                                                                                                                                                     
clip_l = "/app/flux/clip_l.safetensors"                                                                                                                              
discrete_flow_shift = 3.1582                                                                                                                                                   
dynamo_backend = "inductor"                                                                                                                                                          
epoch = 1
full_bf16 = true                                                                                                                                                               
gradient_accumulation_steps = 2                                                                                                                                               
gradient_checkpointing = true                                                                                                                                                  
guidance_scale = 1.0                                                                                                                                                           
highvram = false                                                                                                                                                                
huggingface_path_in_repo = "checkpoint"
huggingface_repo_id = ""
huggingface_repo_type = "model"
huggingface_repo_visibility = "public"
huggingface_token = ""
learning_rate = 1e-5
loss_type = "l2"                                                                                                                                                               
lr_scheduler = "cosine_with_restarts"                                                                                                                                                      
lr_scheduler_args = []                                                                                                                                                         
lr_scheduler_num_cycles = 3
lr_scheduler_power = 1                                                                                                                                                         
max_bucket_reso = 1536                                                                                                                                                        
max_data_loader_n_workers = 2                                                                                                                                                  
max_timestep = 200                                                                                                                                                            
#max_train_steps = 1900
max_train_steps = 500
max_grad_norm = 1.0
mem_eff_save = true                                                                                                                                                            
min_bucket_reso = 256                                                                                                                                                          
mixed_precision = "bf16"                                                                                                                                                       
model_prediction_type = "raw"
network_alpha = 64
network_args = [
    "train_double_block_indices=all",
    "train_single_block_indices=all",
    "train_t5xxl=True",
    "dropout=0.1",
    "enable_embeddings_aug=1",
    "aug_prob=0.15"
]
network_dim = 128
network_module = "networks.lora_flux"
noise_offset_type = "Original"
min_snr_gamma = 5
noise_offset = 0.05
scale_weight_norms = 1.0
optimizer_type = "lion"
optimizer_args = ["weight_decay=0.01", "betas=(0.9,0.999)"]
output_dir = "/app/outputs"                                                                                                                                          
output_name = "last"                                                                                                                                                 
persistent_workers = false
pin_memory = true
pretrained_model_name_or_path = "/app/flux/unet.safetensors"                                                                                                                  
prior_loss_weight = 1                                                                                                                                                          
resolution = "768,768"                                                                                                                                                       
sample_prompts = ""                                                                                                                    
sample_sampler = "euler_a"                                                                                                                                                     
save_every_n_epochs = 30
save_model_as = "safetensors"                                                                                                                                                  
save_precision = "float"                                                                                                                                                       
seed = 42
t5xxl = "/app/flux/t5xxl_fp16.safetensors"                                                                                                                           
t5xxl_max_token_length = 256                                                                                         
text_encoder_lr = [5e-6, 5e-6]                                                                                                                                               
timestep_sampling = "sigmoid"                                                                                                                                                  
train_batch_size = 2                                                                                                                                                          
train_data_dir = ""                                                                                                                               
unet_lr = 1e-5
vae_batch_size = 1                                                                                                                                                            
wandb_run_name = "s56-2"                                                                                                                                              
xformers = true         
